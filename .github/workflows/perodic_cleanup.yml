name: Periodic CI Schema Cleanup

on:
  # æ¯é€±æœˆæ›œæ—¥ã®åˆå‰3æ™‚ï¼ˆUTCï¼‰ã«å®Ÿè¡Œ
  schedule:
    - cron: '0 3 * * 1'
  
  # æ‰‹å‹•å®Ÿè¡Œã‚‚å¯èƒ½
  workflow_dispatch:
    inputs:
      dry_run:
        description: 'Dry run mode (just list schemas without deleting)'
        required: false
        default: 'true'
        type: boolean
      retention_days:
        description: 'Delete schemas older than X days'
        required: false
        default: '7'
        type: string

jobs:
  cleanup-old-schemas:
    runs-on: ubuntu-latest
    
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦å¤‰æ›´ï¼‰
    defaults:
      run:
        working-directory: ./tasty_bytes_dbt_demo
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
        # working-directoryã®å½±éŸ¿ã‚’å—ã‘ãªã„ã‚¢ã‚¯ã‚·ãƒ§ãƒ³
      
      - name: Install dependencies
        run: |
          pip install snowflake-connector-python requests
        # â†‘ ã“ã®ã‚¹ãƒ†ãƒƒãƒ—ã¯working-directoryå†…ã§å®Ÿè¡Œã•ã‚Œã‚‹
      
      - name: Cleanup old CI schemas
        env:
          SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
          SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
          SNOWFLAKE_PASSWORD: ${{ secrets.SNOWFLAKE_PASSWORD }}
          SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
          SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
          SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          GITHUB_REPOSITORY: ${{ github.repository }}
          DRY_RUN: ${{ github.event.inputs.dry_run || 'true' }}
          RETENTION_DAYS: ${{ github.event.inputs.retention_days || '7' }}
        run: |
          python3 << 'PYTHON_SCRIPT'
          import os
          import re
          import requests
          from datetime import datetime, timedelta
          import snowflake.connector
          
          # è¨­å®š
          dry_run = os.environ.get('DRY_RUN', 'true').lower() == 'true'
          retention_days = int(os.environ.get('RETENTION_DAYS', '7'))
          cutoff_date = datetime.now() - timedelta(days=retention_days)
          
          print("=" * 70)
          print(f"ğŸ§¹ Periodic CI Schema Cleanup")
          print("=" * 70)
          print(f"Working directory: {os.getcwd()}")
          print(f"Mode: {'ğŸ” DRY RUN' if dry_run else 'ğŸ”¥ ACTIVE DELETE'}")
          print(f"Retention period: {retention_days} days")
          print(f"Cutoff date: {cutoff_date.strftime('%Y-%m-%d %H:%M:%S')}")
          print()
          
          # GitHub APIã§ã‚ªãƒ¼ãƒ—ãƒ³ä¸­ã®PRã‚’å–å¾—
          github_token = os.environ['GITHUB_TOKEN']
          repo = os.environ['GITHUB_REPOSITORY']
          headers = {
              'Authorization': f'token {github_token}',
              'Accept': 'application/vnd.github.v3+json'
          }
          
          print("ğŸ“‹ Fetching open pull requests from GitHub...")
          try:
              response = requests.get(
                  f'https://api.github.com/repos/{repo}/pulls?state=open',
                  headers=headers
              )
              response.raise_for_status()
              open_prs = {pr['number'] for pr in response.json()}
              print(f"âœ… Found {len(open_prs)} open PRs: {sorted(open_prs) if open_prs else 'none'}")
          except Exception as e:
              print(f"âš ï¸ Failed to fetch PRs from GitHub: {e}")
              print("âš ï¸ Continuing with empty PR list (will only delete old schemas)")
              open_prs = set()
          print()
          
          # Snowflakeæ¥ç¶š
          print("ğŸ”Œ Connecting to Snowflake...")
          conn = snowflake.connector.connect(
              account=os.environ['SNOWFLAKE_ACCOUNT'],
              user=os.environ['SNOWFLAKE_USER'],
              password=os.environ['SNOWFLAKE_PASSWORD'],
              role=os.environ['SNOWFLAKE_ROLE'],
              warehouse=os.environ['SNOWFLAKE_WAREHOUSE'],
              database=os.environ['SNOWFLAKE_DATABASE']
          )
          
          try:
              cursor = conn.cursor()
              database_name = os.environ['SNOWFLAKE_DATABASE']
              
              # CI ã‚¹ã‚­ãƒ¼ãƒã‚’æ¤œç´¢
              print(f"ğŸ” Searching for CI schemas in database: {database_name}")
              cursor.execute(f"""
                  SELECT SCHEMA_NAME, CREATED
                  FROM {database_name}.INFORMATION_SCHEMA.SCHEMATA 
                  WHERE SCHEMA_NAME LIKE 'CI%'
                  ORDER BY CREATED DESC
              """)
              
              schemas = cursor.fetchall()
              print(f"ğŸ“Š Found {len(schemas)} CI-related schemas")
              print()
              
              if not schemas:
                  print("âœ¨ No CI schemas found. Nothing to clean up.")
              else:
                  schemas_to_delete = []
                  schemas_to_keep = []
                  
                  for schema_name, created_on in schemas:
                      # PRç•ªå·ã‚’æŠ½å‡º
                      match = re.search(r'CI[_]?(?:PR[_])?(\d+)', schema_name, re.IGNORECASE)
                      if not match:
                          print(f"âš ï¸ Skipping schema (no PR number found): {schema_name}")
                          continue
                      
                      pr_number = int(match.group(1))
                      
                      # å‰Šé™¤å¯¾è±¡ã®åˆ¤å®š
                      should_delete = False
                      reason = ""
                      
                      if pr_number in open_prs:
                          should_delete = False
                          reason = f"PR #{pr_number} is still open"
                      elif created_on and created_on < cutoff_date:
                          should_delete = True
                          reason = f"Older than {retention_days} days (created: {created_on.strftime('%Y-%m-%d')})"
                      else:
                          should_delete = True
                          reason = f"PR #{pr_number} is closed/merged"
                      
                      if should_delete:
                          schemas_to_delete.append({
                              'name': schema_name,
                              'pr': pr_number,
                              'created': created_on,
                              'reason': reason
                          })
                      else:
                          schemas_to_keep.append({
                              'name': schema_name,
                              'pr': pr_number,
                              'created': created_on,
                              'reason': reason
                          })
                  
                  # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›
                  print("=" * 70)
                  print(f"ğŸ“Š CLEANUP SUMMARY")
                  print("=" * 70)
                  print(f"Total schemas found: {len(schemas)}")
                  print(f"Schemas to keep: {len(schemas_to_keep)}")
                  print(f"Schemas to delete: {len(schemas_to_delete)}")
                  print()
                  
                  if schemas_to_keep:
                      print("âœ… Schemas to KEEP:")
                      for schema in schemas_to_keep:
                          created_str = schema['created'].strftime('%Y-%m-%d %H:%M') if schema['created'] else 'unknown'
                          print(f"  - {schema['name']} (PR #{schema['pr']}, created: {created_str})")
                          print(f"    â†’ {schema['reason']}")
                      print()
                  
                  if schemas_to_delete:
                      print(f"{'ğŸ” Schemas that WOULD BE deleted (DRY RUN):' if dry_run else 'ğŸ—‘ï¸  Schemas to DELETE:'}")
                      for schema in schemas_to_delete:
                          created_str = schema['created'].strftime('%Y-%m-%d %H:%M') if schema['created'] else 'unknown'
                          print(f"  - {schema['name']} (PR #{schema['pr']}, created: {created_str})")
                          print(f"    â†’ {schema['reason']}")
                      print()
                      
                      if not dry_run:
                          print("ğŸ”¥ Deleting schemas...")
                          deleted_count = 0
                          failed_count = 0
                          
                          for schema in schemas_to_delete:
                              try:
                                  drop_sql = f'DROP SCHEMA IF EXISTS "{database_name}"."{schema["name"]}" CASCADE'
                                  cursor.execute(drop_sql)
                                  print(f"  âœ… Deleted: {schema['name']}")
                                  deleted_count += 1
                              except Exception as e:
                                  print(f"  âŒ Failed to delete {schema['name']}: {str(e)}")
                                  failed_count += 1
                          
                          print()
                          print(f"âœ… Cleanup completed!")
                          print(f"   - Successfully deleted: {deleted_count}")
                          if failed_count > 0:
                              print(f"   - Failed: {failed_count}")
                      else:
                          print("â„¹ï¸  DRY RUN mode - No schemas were actually deleted")
                          print("ğŸ’¡ To actually delete these schemas, run with dry_run=false")
                  else:
                      print("âœ¨ No schemas to delete")
                  
                  print("=" * 70)
          
          except Exception as e:
              print(f"âŒ Error: {str(e)}")
              import traceback
              traceback.print_exc()
              raise
          
          finally:
              cursor.close()
              conn.close()
          PYTHON_SCRIPT
      
      - name: Create summary
        if: always()
        run: |
          echo "## ğŸ§¹ CI Schema Cleanup Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Working Directory:** \`./tasty_bytes_dbt_demo\`" >> $GITHUB_STEP_SUMMARY
          echo "**Mode:** ${{ github.event.inputs.dry_run == 'true' && 'ğŸ” DRY RUN' || 'ğŸ”¥ ACTIVE DELETE' }}" >> $GITHUB_STEP_SUMMARY
          echo "**Retention:** ${{ github.event.inputs.retention_days || '7' }} days" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger:** ${{ github.event_name == 'schedule' && 'â° Scheduled' || 'ğŸ‘¤ Manual' }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "Check the logs above for detailed results." >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "ğŸ’¡ **Tips:**" >> $GITHUB_STEP_SUMMARY
          echo "- First run with dry_run=true to see what would be deleted" >> $GITHUB_STEP_SUMMARY
          echo "- Adjust retention_days if needed (default: 7 days)" >> $GITHUB_STEP_SUMMARY
          echo "- This workflow runs automatically every Monday at 3 AM UTC" >> $GITHUB_STEP_SUMMARY
